{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IWM modeler v0.1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "u_IskavHTkhK"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNe9uvs4t6KYa5gJKxo8xTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyslater/Python-Fundamentals/blob/master/IWM_modeler_v0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvIeaGbyGdat"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ophFqV-9hn1F"
      },
      "source": [
        "# GPU install video https://www.youtube.com/watch?v=PitcORQSjNM\n",
        "\"\"\"\n",
        "first get a runtime with a GPU\n",
        "  - Runtime / factory reset runtime\n",
        "  - Runtime / change runtime type\n",
        "\"\"\"\n",
        "!pip install tensorflow-gpu\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"tensorflow version: \",tf.__version__)\n",
        "print(\"keras version: \",keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS0i9EGSwBH6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8x9kKk7w5Z4"
      },
      "source": [
        "%cd /content/drive/MyDrive/'Colab Notebooks'\n",
        "from utils import *\n",
        "%cd /content\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tCDyWgs9d8v"
      },
      "source": [
        "import importlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import text\n",
        "import numbers\n",
        "\n",
        "\n",
        "\n",
        "pd.options.display.float_format = '{:,.4f}'.format\n",
        "pd.set_option(\"display.precision\", 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_IskavHTkhK"
      },
      "source": [
        "## read in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3CEf7Ak9YR2"
      },
      "source": [
        "location = '/content/drive/MyDrive/UCONN/ML Independent Study/project2/data/'\n",
        "options_file = \"IWM Options All.csv\"\n",
        "stocks_file = \"IWM Stocks All.csv\"\n",
        "\n",
        "\n",
        "stocks0 = pd.read_csv(f\"{location}{stocks_file}\")\n",
        "options0 = (pd.read_csv(f\"{location}{options_file}\")).query(\"open_interest>100 | volume>100\")\n",
        "options0['strike_price'] = options0['strike_price'] /1000.\n",
        "options0.rename(columns={'best_offer':'ask', 'best_bid':'bid'}, inplace=True) # buyers get ask price, sellers get the bid price\n",
        "\n",
        "stocks0['date_'] = pd.to_datetime(stocks0['date'].astype(str), format='%Y%m%d')\n",
        "stocks = stocks0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqfMxRI7FASW"
      },
      "source": [
        "# display(stocks0)\n",
        "# options0\n",
        "# display(options0.columns)\n",
        "# display(stocks0.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J44ShFDMC3KG"
      },
      "source": [
        "\n",
        "# combine option and stock price, keep only needed cols\n",
        "options_field_list = 'date,ticker,cp_flag,exdate,strike_price,bid,ask,volume,open_interest,impl_volatility,delta,gamma,vega,theta,optionid'.split(',')\n",
        "for k in 'low,high,open,close,volume'.split(','): stocks[f\"stock_{k}\"] = stocks[k] \n",
        "stock_field_list ='date,stock_low,stock_high,stock_open,stock_close,stock_volume'.split(',')\n",
        "options = pd.merge(left=options0[options_field_list], right=stocks[stock_field_list], how='left', on='date', sort=False).sort_values(by='date,ticker,cp_flag,exdate,strike_price'.split(',')).reset_index(drop=True)\n",
        "\n",
        "# remove cols where any key field is Nan\n",
        "st = len(options)\n",
        "options.dropna(subset='date,ticker,cp_flag,strike_price,bid,ask,volume,open_interest,stock_open'.split(','), inplace=True)\n",
        "en = len(options)\n",
        "if st != en: print(f\"{st-en} rows removed becuase key data is missing from one or more fields\")\n",
        "print(f\"{len(options)} rows in options\")\n",
        "\n",
        "# calc the number of days till exp\n",
        "options['date_'] = pd.to_datetime(options['date'].astype(str), format='%Y%m%d')\n",
        "options['exdate_'] = pd.to_datetime(options['exdate'].astype(str), format='%Y%m%d')\n",
        "options['days'] = (options['exdate_'] - options['date_']).dt.days #https://stackoverflow.com/questions/22132525/add-column-with-number-of-days-between-dates-in-dataframe-pandas/45039811\n",
        "#options.drop(['date_','exdate_'],axis=1,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZPBRglHIfgh"
      },
      "source": [
        "options"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuPfU-TNrrYq"
      },
      "source": [
        "\n",
        "\n",
        "def show_chart(table=pd.DataFrame(),exp_offset=50,shade=None):\n",
        "  # show the stock trend with markers for the options exdates\n",
        "  if len(table) == 0: table = stocks\n",
        "  ax = plot_line(table,'date_', 'close', title=f\"IWM close price and options exdates\", xlabel='date / exdate',ylabel='price',figsize=[40,3],show=0)\n",
        "\n",
        "  # overlay the exdates data\n",
        "  min,max = table.date.min(),table.date.max()\n",
        "  exdates_ = options.query(f\"exdate>={min} & exdate<={max}\").exdate_.unique()\n",
        "  min = table.close.min()\n",
        "  for k in exdates_:  \n",
        "    d = f\"{k}\"[:10]\n",
        "    plt.axvline(x=k, color='g', linestyle='--', linewidth=.75)\n",
        "    plt.text(k, min-exp_offset, d, rotation=90, verticalalignment='center')\n",
        "\n",
        "  if shade: \n",
        "    print(type(table['date_'][0]), pd._libs.tslibs.timestamps.Timestamp)\n",
        "    for i in [0,1]: shade[i] = pd.to_datetime(str(shade[i]), format='%Y%m%d') if type(shade[i]) != pd._libs.tslibs.timestamps.Timestamp else shade[i]\n",
        "    plt.axvspan(shade[0], shade[1], facecolor='b', alpha=0.07)\n",
        "\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuJZgV_AO0yS"
      },
      "source": [
        "# Options Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d77yH_zXO6qf"
      },
      "source": [
        "  class Options():\n",
        "    def __init__(self,options,date=20200513, ticker='IWM', exdate=20200605, change_range=None, id=None, end_date=None, verbose=0):\n",
        "      if id==None: id = date\n",
        "      self.Timer = Timer()\n",
        "      self.verbose = verbose\n",
        "      self.id = id\n",
        "      self.date = date\n",
        "      self.ticker = ticker\n",
        "      self.exdate = exdate\n",
        "      self.change_range = change_range\n",
        "      self.commission = 1.2\n",
        "      self.options = options\n",
        "      self.positions = pd.DataFrame(columns='date,ticker,exdate,buy_strike,buy_ask,sell_strike,sell_bid,name'.split(','))\n",
        "      self.all_positions = pd.DataFrame()\n",
        "      self.cum_outcome = pd.DataFrame()\n",
        "      self.bin_size = 10\n",
        "\n",
        "    def set_state(self,date=None,ticker=None,exdate=None):\n",
        "      if date: self.date = date\n",
        "      if ticker: self.ticker = ticker\n",
        "      if exdate: self.exdate = exdate\n",
        "    def reset_positions(self): self.positions = pd.DataFrame(columns='date,ticker,exdate,buy_strike,buy_ask,sell_strike,sell_bid,name'.split(','))\n",
        "    def reset_all_positions(self): self.all_positions = pd.DataFrame()\n",
        "    def id2name(self,optionid,fields=None):\n",
        "      if fields==None: fields = 'date,ticker,exdate,cp_flag,strike_price'\n",
        "      d = self.options.query(f\"optionid=={optionid}\").to_dict('records')[0]\n",
        "      ret = \"\"\n",
        "      for f in fields.split(','): ret += f\"{d[f]:0.2f} \" if type(d[f])==float else f\"{d[f]} \"\n",
        "      return ret[:-1]\n",
        "    def pname(self): return f\"{str(self.date)[4:]} {self.ticker} {str(self.exdate)[4:]}\" \n",
        "    def position2name(self,d,fields=None):\n",
        "      if fields==None: fields = 'date,ticker,exdate,buy_strike,sell_strike'\n",
        "      ret = \"\"\n",
        "      for f in fields.split(','): ret += f\"{d[f]:0.2f} \" if type(d[f])==float else f\"{d[f]} \"\n",
        "      return ret[:-1]\n",
        "\n",
        "    def dfsave(self,df,name,folder=None):\n",
        "      path = f\"/content/drive/MyDrive/{folder}/\"\n",
        "      df.to_csv(name, index=False)\n",
        "      !cp $name $path # assumes drive has been mounted\n",
        "    def dfrestore(self,name,folder=None): return pd.read_csv(f\"/content/drive/MyDrive/{folder}/{name}\")\n",
        "    def save_state(self,id=None):\n",
        "      if id==None: id = self.id\n",
        "      f = f\"Options_{id}_\"\n",
        "      folder = 'COLAB_SAVE'\n",
        "      self.dfsave(self.positions,f\"{f}positions.csv\", folder=folder)\n",
        "      self.dfsave(self.all_positions,f\"{f}all_positions.csv\", folder=folder)\n",
        "      print(f\"saved state to {folder}/{f}*\")\n",
        "    def restore_state(self,id=None):\n",
        "      if id==None: id = self.id\n",
        "      print(f\"restoring state {id}\")\n",
        "      self.positions = self.dfrestore(f\"Options_{id}_positions.csv\",folder='COLAB_SAVE')\n",
        "      self.all_positions = self.dfrestore(f\"Options_{id}_all_positions.csv\",folder='COLAB_SAVE')\n",
        "\n",
        "\n",
        "\n",
        "    def get_PUT_strikes(self,date=None,ticker=None,exdate=None,strikes=None): return self.get_strikes(date,ticker,exdate,strikes=strikes,cp_flag='P')\n",
        "    def get_CALL_strikes(self,date=None,ticker=None,exdate=None,strikes=None): return self.get_strikes(date,ticker,exdate,strikes=strikes,cp_flag='C')\n",
        "    def get_strikes(self,date,ticker,exdate,cp_flag=None,strikes=None):\n",
        "      self.set_state(date,ticker,exdate)\n",
        "      ret = self.options.query(f\"date=={self.date} & ticker=='{self.ticker}' & exdate=={self.exdate}\")\n",
        "      if cp_flag: ret = ret.query(f\"cp_flag=='{cp_flag}'\")\n",
        "      if strikes != None: \n",
        "        if type(strikes) == str: strikes = strikes.split(',')\n",
        "        elif isinstance(strikes, numbers.Number): strikes =[strikes,]\n",
        "        ret = ret[ret.strike_price.isin(strikes)]\n",
        "      return ret\n",
        "\n",
        "    def get_exdates(self,date=None,max_exdate=None,ticker=None):\n",
        "      self.set_state(date,ticker)\n",
        "      ret = options.query(f\"date=={self.date} & ticker=='{self.ticker}'\")\n",
        "      if max_exdate: ret = ret.query(f\"exdate <= {max_exdate}\")\n",
        "      return ret.exdate.unique()\n",
        "\n",
        "    def get_dates(self,start_date=None,end_date=None,cnt=None,step=1):\n",
        "      p = self.options\n",
        "      if start_date: p = p.query(f\"date>={start_date}\")\n",
        "      if end_date: p = p.query(f\"date<={end_date}\")\n",
        "      p = p['date'].unique()\n",
        "      p.sort()\n",
        "      if cnt: p = p[:cnt*step:step]\n",
        "      return p\n",
        "\n",
        "    def add_bps_position(self,date=None,ticker=None,exdate=None,buy_strike=None,sell_strike=None):\n",
        "      self.set_state(date,ticker,exdate)\n",
        "      if not buy_strike or not sell_strike: \n",
        "        print(\"buy and sell strike required\")\n",
        "        return\n",
        "      idx = len(self.positions)\n",
        "      # add only if its not already there\n",
        "      present = len(self.positions.query(f\"date=={self.date} & ticker=='{self.ticker}' & exdate=={self.exdate} &buy_strike=={buy_strike} & sell_strike=={sell_strike}\")) >0\n",
        "      if not present: \n",
        "        name = f\"{str(self.date)[4:]} {self.ticker} {str(self.exdate)[4:]} {buy_strike:0.2f} {sell_strike:0.2f}\"\n",
        "        self.positions.loc[idx] = {'name': name, 'date': self.date, 'ticker': self.ticker, 'exdate': self.exdate, 'buy_strike': buy_strike, 'sell_strike': sell_strike }\n",
        "\n",
        "    # loop over all possible combinations for the given date,ticker and exdate\n",
        "    def OLD_make_position_table(self,limit=0,reset_all=1,add2all=0, verbose=0):\n",
        "      self.Timer.start('make_position_table')\n",
        "      if reset_all:\n",
        "        self.reset_all_positions()\n",
        "        self.reset_positions()\n",
        "      #put_strikes = self.get_PUT_strikes().query(\"open_interest>100 | volume>100\")\n",
        "      put_strikes = self.get_PUT_strikes()\n",
        "      sell_strikes =  put_strikes.strike_price.unique()[:-1]\n",
        "      if verbose: print(f\"{len(sell_strikes)+1} strikes for {self.date} {self.ticker} {self.exdate}\")\n",
        "      i = 0\n",
        "      for ss in sell_strikes:\n",
        "        buy_strikes =  put_strikes.query(f\"strike_price>{ss}\").strike_price.unique()\n",
        "        for bs in buy_strikes: \n",
        "          #if i%100==0: print(ss,bs, end='\\r')\n",
        "          self.add_bps_position(buy_strike=bs,sell_strike=ss)\n",
        "          i += 1\n",
        "          if limit and i>=limit: break\n",
        "        if limit and i>=limit: break\n",
        "      if verbose: print(f\"{i} positions added\")\n",
        "      self.Timer.stop('make_position_table')\n",
        "      return\n",
        "\n",
        "    \n",
        "    # loop over all possible combinations for the given date,ticker and exdate\n",
        "    def make_position_table(self,limit=0,reset_all=1,add2all=0, verbose=0):\n",
        "      self.Timer.start('make_position_table')\n",
        "      if reset_all:\n",
        "        self.reset_all_positions()\n",
        "        self.reset_positions()\n",
        "      #put_strikes = self.get_PUT_strikes().query(\"open_interest>100 | volume>100\")\n",
        "      put_strikes = self.get_PUT_strikes()\n",
        "      sell_strikes =  put_strikes.strike_price.unique()[:-1]\n",
        "      if verbose: print(f\"{len(sell_strikes)+1} strikes for {self.date} {self.ticker} {self.exdate}\")\n",
        "      i = 0\n",
        "      dlist = []\n",
        "      for ss in sell_strikes:\n",
        "        buy_strikes =  put_strikes.query(f\"strike_price>{ss}\").strike_price.unique()\n",
        "        for bs in buy_strikes: \n",
        "          #if i%100==0: print(ss,bs, end='\\r')\n",
        "  #        self.add_bps_position(buy_strike=bs,sell_strike=ss)\n",
        "          name = f\"{str(self.date)[4:]} {self.ticker} {str(self.exdate)[4:]} {bs:0.2f} {ss:0.2f}\"\n",
        "          dlist.append( {'name': name, 'date': self.date, 'ticker': self.ticker, 'exdate': self.exdate, 'buy_strike': bs, 'sell_strike': ss } )\n",
        "          i += 1\n",
        "          if limit and i>=limit: break\n",
        "        if limit and i>=limit: break\n",
        "      if verbose: print(f\"{i} positions added\")\n",
        "      dfadd = pd.DataFrame(dlist)\n",
        "      self.positions = pd.concat([self.positions,dfadd],axis=0).reset_index(drop=True).drop_duplicates()    \n",
        "      self.Timer.stop('make_position_table')\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "    def update_bps_position(self,plot_range=None,add2all=0, verbose=0):\n",
        "      self.Timer.start('update_bps_position')\n",
        "      for loopbreak in [1]:\n",
        "        if len(self.positions) == 0:\n",
        "          print(\"no positions\")\n",
        "          break\n",
        "\n",
        "        pfields = 'date,ticker,exdate,buy_strike,sell_strike,name'.split(',')\n",
        "        ofields ='date,ticker,stock_open,exdate,strike_price,optionid'.split(',')\n",
        "\n",
        "        # get the option SELL data\n",
        "        strikes = list(self.positions.sell_strike.unique()) # get the sell strikes for all exp\n",
        "        puts = self.get_PUT_strikes(strikes=strikes) # get all the puts to so we can add this data to the positions\n",
        "        self.positions = pd.merge(left=self.positions[pfields], right=puts[ofields+['bid','ask']], how='left', left_on='date,ticker,exdate,sell_strike'.split(','), right_on='date,ticker,exdate,strike_price'.split(',') ,sort=False)\n",
        "        self.positions.rename(columns={'optionid':'sell_optionid','bid':'sell_bid','ask':'sell_ask'}, inplace=True)\n",
        "\n",
        "        # could be the case where a SELL strike_price was added to the position list, but there is no option. So remove them\n",
        "        # x = len(self.positions.query(\"sell_bid != sell_bid\")) # rows that aare Nan\n",
        "        # print('SELL NAN=',x)\n",
        "        self.positions.dropna(inplace=True)\n",
        "        if len(self.positions) == 0: break\n",
        "\n",
        "        # calc the change% \n",
        "        self.positions['change_pc'] = 100*(self.positions.sell_strike/self.positions.stock_open -1).astype(float) # must do astype becasue of bug, otherwise .query(\"change_pc>-1.5\") generates an error https://stackoverflow.com/questions/50400843/using-negative-numbers-in-pandas-dataframe-query-expression\n",
        "\n",
        "        # remove any rows that do not meet the change_range - dont want to computer and store garbage\n",
        "        st = len(self.positions)\n",
        "        if self.change_range: self.positions = self.positions.query(f\"(change_pc <= {self.change_range[1]}) & (change_pc >= {self.change_range[0]})\")\n",
        "        fn = len(self.positions)\n",
        "        if verbose and st!=fn: print(f\"{fn} rows in sell_strikes after {st-fn} rows removed because change_pc is not within the change_range {self.change_range}\")\n",
        "        if not fn: break\n",
        "\n",
        "        # fill optoin BUY strike data\n",
        "        strikes = list(self.positions.buy_strike.unique()) # get the sell strikes for all exp\n",
        "        puts = self.get_PUT_strikes(strikes=strikes) # get all the puts to so we can add this data to the positions\n",
        "        self.positions = pd.merge(left=self.positions[pfields +'sell_bid,sell_ask,change_pc,sell_optionid'.split(',')], right=puts[ofields+['bid','ask','days',]], how='left', left_on='date,ticker,exdate,buy_strike'.split(','), right_on='date,ticker,exdate,strike_price'.split(',') ,sort=False)\n",
        "        self.positions.rename(columns={'optionid':'buy_optionid','bid':'buy_bid','ask':'buy_ask'}, inplace=True)\n",
        "\n",
        "        # could be the case where a BUY strike_price was added to the position list, but there is no option. So remove them\n",
        "        #x = len(self.positions.query(\"buy_bid != buy_bid\")) # rows that aare Nan\n",
        "        #print(f\"removing {x} rows where buy strike_price not found in options list\")\n",
        "        self.positions.dropna(inplace=True)\n",
        "        if len(self.positions) == 0: break\n",
        "\n",
        "        # rename \n",
        "        #self.positions.dropna(inplace=True, axis=0) # should never need to do this\n",
        "        self.positions.rename(columns={'stock_open':'stock_price'}, inplace=True)\n",
        "\n",
        "        # calc remaining stuff\n",
        "        self.positions['cost'] = 100*(self.positions.buy_ask - self.positions.sell_bid) + self.commission\n",
        "        self.positions['max_profit'] = 100*(self.positions.buy_strike -self.positions.sell_strike) -self.positions.cost\n",
        "        self.positions['max_ROI_pc'] = (100 * self.positions.max_profit / self.positions.cost).astype(int)\n",
        "\n",
        "        # REMOVE CRAZY STUFF\n",
        "        self.positions = self.positions.query(\"cost<=350\")\n",
        "\n",
        "        # reorder and sort fields\n",
        "        self.positions = self.positions['date,ticker,stock_price,exdate,days,buy_strike,sell_strike,buy_ask,sell_bid,buy_bid,sell_ask,cost,max_profit,max_ROI_pc,change_pc,buy_optionid,sell_optionid,name'.split(',')].sort_values(by='change_pc,max_ROI_pc'.split(',')).reset_index(drop=True)\n",
        "        \n",
        "        if plot_range: self.plot_table(change_range=plot_range)\n",
        "        if add2all: \n",
        "          if len(self.all_positions) == 0: self.all_positions = self.positions.copy()\n",
        "          else: \n",
        "            self.all_positions = self.all_positions.query( f\"not ( date=={self.date} & ticker=='{self.ticker}' & exdate=={self.exdate})\" )  # delete all currently inall\n",
        "            self.all_positions = self.all_positions.append(self.positions,ignore_index=True)\n",
        "      self.Timer.stop('update_bps_position')\n",
        "      return \n",
        "\n",
        "    def get_options_from_positions(self,table=pd.DataFrame()):\n",
        "      # stack the buy and sell stikes so they are not combined in any rows. just get all options involved in any side of the bps\n",
        "      if len(table) == 0: table = self.all_positions\n",
        "      df1 = table.groupby('date,ticker,exdate,buy_strike'.split(',')).size().reset_index(name='F1').rename(columns={'buy_strike':'strike_price'})\n",
        "      df2 = table.groupby('date,ticker,exdate,sell_strike'.split(',')).size().reset_index(name='F2').rename(columns={'sell_strike':'strike_price'})\n",
        "      df = pd.merge(df1,df2, indicator=True, how='outer', on='date,ticker,exdate,strike_price'.split(',')).query('_merge==\"left_only\"').drop('_merge,F1,F2'.split(','), axis=1)\n",
        "      # merge back the options data\n",
        "      df = pd.merge(df,self.options[self.options.cp_flag=='P'], how='left', on='date,ticker,exdate,strike_price'.split(','))\n",
        "      return df\n",
        "\n",
        "    def make_best_positions(self,dates,max_exdate_distance=30,limit=0,verbose=0):\n",
        "      self.Timer.start('make_best_positions')\n",
        "      # loop though all the dates building all possible combinations of BPS within the expiration date limits\n",
        "      # select only the best postions for each date\n",
        "      p = pd.DataFrame()\n",
        "      i = 0\n",
        "      for date in dates: # this is the date in time when we are placing the bet\n",
        "        i += 1\n",
        "        self.set_state(date=date) # set the new date\n",
        "        max_exdate = add_days(date, max_exdate_distance)\n",
        "        exdates = self.get_exdates(max_exdate=max_exdate)\n",
        "        if verbose: hprint(f\"\\nfor {date} there are {len(exdates)} exdates within {max_exdate_distance} days: {exdates}\") \n",
        "        if verbose>1: print(f\"date: {date}, max_exdate: {max_exdate}, exdates={exdates}\")\n",
        "\n",
        "        for exdate in exdates:\n",
        "          if exdate == date: continue\n",
        "          if verbose: print(f\"\\nexp={exdate}\")\n",
        "          self.reset_positions() # clear out positions\n",
        "          self.set_state(date=date,exdate=exdate) # set the new exdate\n",
        "          self.make_position_table(limit=limit,reset_all=0, verbose=verbose) # all combinations for the date, ticker and exdate\n",
        "          self.update_bps_position(add2all=1, verbose=verbose) # add in the options data\n",
        "        #  op.plot_positions_ROI(table=op.all_positions)\n",
        "\n",
        "        p = self.all_positions\n",
        "\n",
        "        if False:\n",
        "          # select only the best from each exdate for this date\n",
        "          if len(self.all_positions) == 0:\n",
        "            hprint(f\"there are no positions that meet the requirements dates={dates}, max_exdate_distance={max_exdate_distance}, limit={limit}\")\n",
        "            break\n",
        "          fields = 'date,exdate,change_pc'.split(',')\n",
        "          st = len(p)\n",
        "          p = p.loc[p.groupby(fields)['max_ROI_pc'].idxmax()] # keep only the max value fo each groupby\n",
        "          en = len(p)\n",
        "          if verbose>1 and st != en: print(f\"{st-en} total positions removed because they are not optimal\")\n",
        "\n",
        "        print(f\"finished date={date} ({i}/{len(dates)}) total positions={len(p)} elapsed_time={self.Timer.etime()}\")\n",
        "        if verbose: self.Timer.report()\n",
        "      self.Timer.stop('make_best_positions')\n",
        "      return p\n",
        "\n",
        "    def make_derived(self,t=pd.DataFrame()):\n",
        "      # derived data is also calculated elsewhere earlier in the processes. This is the final \n",
        "      if len(t) == 0: t = self.positions\n",
        "      t['strike_spread'] = t['buy_strike'] - t['sell_strike']\n",
        "      t['stock_spread'] = t['buy_strike'] - t['stock_price']\n",
        "      t['buy_bid_ask_spread'] = 100 * (t['buy_ask'] - t['buy_bid']) / t['buy_strike']\n",
        "      t['sell_bid_ask_spread'] = 100 * (t['sell_ask'] - t['sell_bid']) / t['sell_strike']\n",
        "\n",
        "    def update_position_outcome(self,positions,verbose=0):\n",
        "      # given the positions, calculate the outcome\n",
        "      commission = self.commission\n",
        "      # merge in the stock close price\n",
        "      ptable = pd.merge(positions,stocks0['date,stock_close'.split(',')].rename(columns={'date':'exdate'}), on='exdate', sort=False)\n",
        "      # three scenarios for excercise , stock is below sell_strike, above_buy_strike, or betweek\n",
        "      ptable.loc[ptable.stock_close<=ptable.sell_strike, 'outcome'] = 100*(ptable['buy_strike'] - ptable['sell_strike'] - (ptable['buy_ask'] -ptable['sell_bid']) ) -commission\n",
        "      ptable.loc[ptable.stock_close>=ptable.buy_strike, 'outcome'] = -100*(ptable['buy_ask'] -ptable['sell_bid'])  -commission\n",
        "      ptable.loc[(ptable.stock_close<ptable.buy_strike) & (ptable.stock_close>ptable.sell_strike), 'outcome'] = 100*(ptable['buy_strike'] - ptable['stock_close'] - (ptable['buy_ask'] -ptable['sell_bid']) )-commission\n",
        "      # sort it\n",
        "      ptable = ptable['date,ticker,exdate,outcome,days,stock_price,stock_close,buy_strike,sell_strike,buy_ask,sell_bid,buy_bid,sell_ask,cost,max_profit,max_ROI_pc,change_pc,buy_optionid,sell_optionid,name'.split(',')].sort_values(by='outcome,date,name'.split(','))\n",
        "      #hprint('ptable'); display(ptable)\n",
        "      if verbose: \n",
        "        min, max = positions.date.min(), positions.exdate.max()\n",
        "        hprint(f\"outcome: {ptable.outcome.sum():0.2f}, min exdate: {min}, max exdate: {max}, positions:{len(positions)}\")\n",
        "      return ptable\n",
        "\n",
        "    def make_cum_outcome(self,results=pd.DataFrame(),bin_size=None):\n",
        "      if bin_size: self.bin_size = bin_size\n",
        "      if len(results)==0: results = self.positions\n",
        "      # calc cum distribution\n",
        "      outcome = []\n",
        "      roi = []\n",
        "      max_outcome = results.outcome.sum()\n",
        "      for r in range(int(2000/self.bin_size)+1):\n",
        "        cum_roi = r*self.bin_size\n",
        "        roi.append(cum_roi)\n",
        "        cum_outcome = results[results.max_ROI_pc<cum_roi].outcome.sum()\n",
        "        outcome.append(cum_outcome)\n",
        "        if cum_outcome/max_outcome > 0.95: \n",
        "          #print(\"breaking\", r, cum_outcome, max_outcome)\n",
        "          break # dont need to see more than this\n",
        "      cd = pd.DataFrame()\n",
        "      cd['roi'] = roi\n",
        "      cd['outcome'] = outcome\n",
        "      self.cum_outcome = cd\n",
        "      max_cum_roi = cd['outcome'].idxmax()\n",
        "      hprint(f\"\\noutcome is increasing until {max_cum_roi*self.bin_size} with a cumulative outcome of ${cd.outcome[max_cum_roi]:0.0f}\")\n",
        "      self.plot_cum_outcome()\n",
        "\n",
        "\n",
        "    def build_dataset(self,start_date=None, end_date=None, max_days=None, step_days=1, limit=0,positions=pd.DataFrame()):\n",
        "      self.Timer.start('build_dataset')\n",
        "      # given inputs, make all the postions, calculate the outcomes, plot to retuls, along with the cumulative outcome v. max_ROI_pc\n",
        "      dates = self.get_dates(start_date=start_date, end_date=end_date, cnt=max_days, step=step_days) \n",
        "      hprint(f\"Processing {len(dates)} dates: {dates}\")\n",
        "      # make all the positions, select the best ones\n",
        "      if len(positions) == 0: self.positions = self.make_best_positions(dates,max_exdate_distance=max_exdate_distance,limit=limit, verbose=0)\n",
        "      else: self.positions = positions\n",
        "      hprint(f\"{len(self.positions)} postions of {len(self.all_positions)} selected\")\n",
        "      # update the outcome and addtional derived data for the positions\n",
        "      self.positions = self.update_position_outcome(self.positions)\n",
        "      make_derived(self.positions) #\n",
        "      self.save_state()\n",
        "      \n",
        "      # output the plots\n",
        "      min, max = self.positions.date.min(), self.results.exdate.max()\n",
        "      hprint(f\"outcome: {self.positions.outcome.sum():0.0f}, min exdate: {min}, max exdate: {max}, positions:{len(self.positions)}\")\n",
        "      plot_points(self.positions,'max_ROI_pc',fields='outcome',title='outcome v. max_ROI_pc', ylabel='Outcome ($)',xlabel='max_ROI_pc',figsize=[20,5])\n",
        "      self.make_cum_outcome(self.positions)\n",
        "      self.Timer.stop('build_dataset')\n",
        "      self.Timer.report()\n",
        "\n",
        "    def plot_cum_outcome(self,cum_outcome=pd.DataFrame()): \n",
        "      if len(cum_outcome)==0 : cum_outcome = self.cum_outcome\n",
        "      if len(cum_outcome)==0: cum_outcome = self.cum_outcome = self.make_cum_outcome()\n",
        "      plot_points(cum_outcome,'roi',fields='outcome',title='cumulative outcome v. max_ROI_pc', ylabel='cumulative outcome ($)',xlabel='max_ROI_pc',figsize=[20,5])\n",
        "\n",
        "    def plot_ROI_v_outcome(self,results=pd.DataFrame()):\n",
        "      if len(results) ==0: results = self.positions\n",
        "      plot_points(results,'max_ROI_pc',fields='outcome',title='outcome v. max_ROI_pc', ylabel='Outcome ($)',xlabel='max_ROI_pc',figsize=[20,5])\n",
        "\n",
        "    # was plot_table\n",
        "    def plot_positions_ROI(self,date=None,ticker=None,exdate=None,change_range=None,xlim=None,ylim=None,title=None,figsize=[20,3],table=pd.DataFrame()):\n",
        "      # plot the table. x-axis is %change, y-axis ROI%, will plot each exdate. usual should only have one ticker and one date and one exdate in the table\n",
        "      if len(table)==0: table = self.positions\n",
        "      fig, ax = plt.subplots(figsize=(figsize))\n",
        "      #fig = plt.figure()\n",
        "      if change_range: table = table.query(f\"(change_pc <= {change_range[1]}) & (change_pc >= {change_range[0]})\")\n",
        "      if len(table) == 0: return None\n",
        "      plt.xlabel(f\"%change in stock price\")\n",
        "      plt.ylabel('Max ROI %')\n",
        "      for date in table.date.unique():\n",
        "        t = table[table.date==date][['change_pc','max_ROI_pc','exdate']]\n",
        "        exdates = t.exdate.unique()\n",
        "        for exd in exdates:\n",
        "          t2 = t[t.exdate==exd]\n",
        "          plt.plot(t2['change_pc'],t2['max_ROI_pc'],'o', label=f\"{date} {self.ticker} {exd}\"); \n",
        "      plt.grid()\n",
        "      if title==None: title = f\"{self.date} {self.ticker} {self.exdate if len(exdates)==1 else ''}\"\n",
        "      plt.legend()\n",
        "      plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "      plt.title(title) \n",
        "      ax.set_xlim(xlim)\n",
        "      ax.set_ylim(ylim)\n",
        "      p = plt.show()\n",
        "      return table\n",
        "\n",
        "    def plot_greek(self,table,letter):\n",
        "      # gien all_positions get the options for all buy_strike and sell_strikes and then plot the greeks over the strike price\n",
        "      fig, ax = plt.subplots()\n",
        "      for exp in table.exdate.unique():\n",
        "        ax.plot( table[table.exdate==exp].strike_price, table[table.exdate==exp][letter], label=f\"exdate={exp}\")\n",
        "      ax.set(xlabel='strike_price', ylabel=letter, title=letter)\n",
        "      ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "      ax.grid()\n",
        "      plt.show()\n",
        "    def plot_greeks(self,table=pd.DataFrame()):\n",
        "      table = self.get_options_from_positions(table)\n",
        "      for g in 'impl_volatility,delta,gamma,vega,theta'.split(','):\n",
        "        self.plot_greek(table,g)\n",
        "\n",
        "    def test(self):\n",
        "      op = Options(options, date=20200513, ticker='IWM', exdate=20200605, change_range=[-3.1, 0])\n",
        "      op.add_bps_position(buy_strike=128,sell_strike=123)\n",
        "      op.add_bps_position(buy_strike=127,sell_strike=123)\n",
        "      op.update_bps_position()\n",
        "      print(len(op.positions), len(op.all_positions))\n",
        "      op.positions\n",
        "      op.all_positions\n",
        "      op.plot_greeks()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEtG9Sr6X7sZ"
      },
      "source": [
        "show_chart(stocks0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZL32Jz9Kf0i"
      },
      "source": [
        "#generate data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySaLSpgoh1R8"
      },
      "source": [
        "if False:\n",
        "  # start_date = 20190101\n",
        "  # end_date = 20201231\n",
        "  step_days = 1\n",
        "  max_days = None\n",
        "  max_exdate_distance = 30 # place bets on exdates at most this many days out from date bet is being placed\n",
        "  op = Options(options, id='generator', date=None, ticker='IWM') #, change_range=[-10,0]\n",
        "  op.build_dataset(start_date=None, end_date=None, max_days=max_days, step_days=step_days, limit=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JEhiWmOG4jG"
      },
      "source": [
        "# Build the Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8jd9QIfHADv"
      },
      "source": [
        "op = Options(options, id='generator0', date=None)\n",
        "op.restore_state()\n",
        "#op.positions.drop(['name'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUKC5xedaK6n"
      },
      "source": [
        "op.positions.date.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0ox_6tn5BTU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class OptionModel_1():\n",
        "  def __init__(self,positions,train_start_date=None, train_days=None, test_start_date=None, test_days=None, verbose=0):\n",
        "    self.positions = positions\n",
        "\n",
        "    self.investment = 10000 # total initial investment\n",
        "    self.max_exp_days = 30 # maximum days till the expiration date (closing the investment)\n",
        "    self.train_start_date = train_start_date # start training date\n",
        "    self.train_days = train_days # number of days to train\n",
        "    self.test_start_date = test_start_date # start of test date (test continues for time_period days)\n",
        "    self.test_days = test_days # number of days over which test should be run\n",
        "    self.max_change = None\n",
        "\n",
        "    # training set\n",
        "    if self.train_start_date == None: self.train_start_date = self.positions.loc[0]['date']\n",
        "    if self.train_days == None: self.train_days = 120\n",
        "    self.train_end_date = sorted(self.positions.date.unique())[self.train_days]\n",
        "    self.train_set = self.positions.query(f\"date<={self.train_end_date}\").query(f\"exdate<={self.train_end_date}\")\n",
        "    self.train_set = self.date2sequence(self.train_set)\n",
        "    self.X_train, self.y_train = self.makeXy(self.train_set)\n",
        "\n",
        "    # test set\n",
        "    if self.test_start_date == None: self.test_start_date = add_days( self.train_end_date, 1 )\n",
        "    if self.test_days == None: self.test_days = int(self.train_days/4.0)\n",
        "    self.test_end_date = sorted(self.positions.date.unique())[self.train_days +self.test_days]\n",
        "    self.test_set = self.positions.query(f\"date>{self.train_end_date} & date<={self.test_end_date}\").query(f\"exdate<={self.test_end_date}\")\n",
        "    self.test_set = self.date2sequence(self.test_set)\n",
        "    self.X_test, self.y_test = self.makeXy(self.test_set)\n",
        "\n",
        "    if verbose:\n",
        "      print( \"state: \", d2print( self.__dict__) )\n",
        "      print( f\"All data: {len(self.positions)} train_set: {len(self.train_set)} test_set: {len(self.test_set)} \") \n",
        "\n",
        "    # X_train = d.query(\"position < 11\")[input_fields]\n",
        "    # X_test = d.query(\"position >= 11\")[input_fields]\n",
        "    # y_train = d.query(\"position < 11\")[f\"anchor{anchor}\"]\n",
        "    # y_test = d.query(\"position >= 11\")[f\"anchor{anchor}\"]\n",
        "\n",
        "  def makeXy(self,df):\n",
        "    normalize_fields = 'days,stock_price,stock_close,buy_strike,sell_strike,buy_ask,sell_bid,sell_ask,cost,max_profit,max_ROI_pc,change_pc,strike_spread,stock_spread,buy_bid_ask_spread,sell_bid_ask_spread'.split(',')\n",
        "    X = df[normalize_fields].copy()\n",
        "    y = df['outcome'].copy()\n",
        "    # how to easily buketize this into say 5 bins so we have ranges of outcomes and then have a softmax as the output \n",
        "    y[ y > 0] = .99 # for anything greater then 0 set it to .99, why does this have to be .99\n",
        "    y[ y < 0] = 0\n",
        "    dfnormalize_fields(X,normalize_fields)\n",
        "    return X,y\n",
        "\n",
        "  def date2sequence(self,t,new_field='day'):\n",
        "    # add a new field that is simply an incredmenting number for the day\n",
        "    dates = np.sort(t.date.unique())\n",
        "    df = pd.DataFrame(columns=['date'],data=dates)\n",
        "    df[new_field] = df.index\n",
        "    return t.merge(df,how='left',on='date')\n",
        "\n",
        "\n",
        "\n",
        "om = OptionModel_1(positions=op.positions.drop('name,buy_optionid,sell_optionid'.split(','),axis=1).sort_values('date,exdate,sell_strike,buy_strike'.split(',')).reset_index(drop=True) )\n",
        "\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(linewidth=180)\n",
        "\n",
        "\n",
        "if False:\n",
        "  plimit = 3\n",
        "  hprint(\"\\nX_train\"); display(om.X_train[:plimit].to_numpy())\n",
        "  hprint(\"\\ny_train\"); display(om.y_train[:plimit])\n",
        "  hprint(\"\\nX_test\"); display(om.X_test[:plimit])\n",
        "  hprint(\"\\ny_test\"); display(om.y_test[:plimit])\n",
        "  om.y_train.describe()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeR6AUDPNzIt"
      },
      "source": [
        "#om.test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEaB6Xu0RoKB"
      },
      "source": [
        "om.X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGyXGX2GokLg"
      },
      "source": [
        "num_features = len(om.X_train.columns)\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Flatten(input_shape=[1, num_features]),\n",
        "  keras.layers.Dense(num_features*2, activation=\"relu\"),\n",
        "  keras.layers.Dense(num_features, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"relu\") # use a softmax of 2 to get some level of uncertainty\n",
        "#  keras.layers.Dense(10, activation=\"softmax\") \n",
        "])\n",
        "\n",
        "fprint(\"notice this is overfit. the loss is 0 right away. \")\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "history = model.fit(om.X_train.to_numpy(), om.y_train.to_numpy(), epochs=30, validation_data=(om.X_test.to_numpy(), om.y_test.to_numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kui_2asWB6q8"
      },
      "source": [
        "X_new = om.X_test.copy()\n",
        "y_proba = (100*model.predict(X_new)).round(0)\n",
        "X_new['y_hat'] = y_proba\n",
        "hprint(\"heres what the predicted outcome looks like for ALL OUTCOMES\")\n",
        "display(X_new.y_hat.describe())\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True)\n",
        "X_new.y_hat.hist()\n",
        "plt.suptitle(\"outcome ROI percent frequency -- ALL\")\n",
        "fig.text(0.5, 0.04, 'predicted outcome ROI', ha='center')\n",
        "fig.text(0.04, 0.5, 'frequency', va='center', rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "hprint(\"\\nheres what the predicted outcome looks like for ALL positive OUTCOMES\")\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True)\n",
        "X_new.query(\"y_hat>0\").y_hat.hist()\n",
        "plt.suptitle(\"outcome ROI percent frequency -- where outcome >0\")\n",
        "fig.text(0.5, 0.04, 'predicted outcome ROI', ha='center')\n",
        "fig.text(0.04, 0.5, 'frequency', va='center', rotation='vertical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2IJfaNNO0dp"
      },
      "source": [
        "om.positions.columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eehmWLf8ckni"
      },
      "source": [
        "X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOXb2KB1c2To"
      },
      "source": [
        "t.query(\"y_hat>0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOlRBGTCtYkc"
      },
      "source": [
        "\n",
        "all = om.positions.merge(X_new.y_hat, how='left', left_index=True, right_index=True)['date,exdate,stock_price,stock_close,outcome,y_hat,days,cost,max_profit,max_ROI_pc,change_pc'.split(',')]\n",
        "invest_wrong = t.query(\"y_hat>0 and outcome<0\")\n",
        "invest_correct = t.query(\"y_hat>0 and outcome>0\")\n",
        "hprint(f\"{len(invest_wrong)} wrong investment predictions\")\n",
        "display(invest_wrong)\n",
        "\n",
        "hprint(f\"{len(invest_correct)} correct investment predictions\")\n",
        "display(invest_correct)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}